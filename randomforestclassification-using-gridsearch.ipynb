{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/learn-together/sample_submission.csv\n",
      "/kaggle/input/learn-together/test.csv\n",
      "/kaggle/input/learn-together/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Read the data and save it in a dataframe\n",
    "\n",
    "# Use r when data is stored locally on your haard drive\n",
    "##X_train = pd.read_csv(r'C:\\Users\\Murphy\\Desktop\\Kaggle Forestry\\learn-together\\train.csv', index_col = 'Id')\n",
    "##X_test  = pd.read_csv(r'C:\\Users\\Murphy\\Desktop\\Kaggle Forestry\\learn-together\\test.csv',  index_col = 'Id')\n",
    "##X_test_full  = pd.read_csv(r'C:\\Users\\Murphy\\Desktop\\Kaggle Forestry\\learn-together\\test.csv')\n",
    "X_train = pd.read_csv(\"/kaggle/input/learn-together/train.csv\", index_col = 'Id')\n",
    "X_test = pd.read_csv(\"/kaggle/input/learn-together/test.csv\", index_col = 'Id')\n",
    "X_test_full = pd.read_csv(\"/kaggle/input/learn-together/test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target object and call it y\n",
    "y = X_train.Cover_Type\n",
    "\n",
    "# Create feature object and call it X. Drop what we are trying to predict\n",
    "X = X_train.drop(columns = 'Cover_Type')\n",
    "\n",
    "# Split into test and training data\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565892, 54)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3024, 54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a variable to hold select feature names in case we want to drop some features\n",
    "Print them using the .columns method then copy into the feature_name variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
      "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
      "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
      "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
      "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
      "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
      "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
      "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
      "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
      "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
      "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
      "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
      "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
      "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
      "       'Soil_Type39', 'Soil_Type40', 'Cover_Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_titles = X_train.columns\n",
    "print(feature_titles)\n",
    "feature_name1 = [ 'Elevation', 'Aspect', 'Slope',\n",
    "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\n",
    "feature_name2 = ['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
    "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
    "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
    "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
    "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
    "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15121</td>\n",
       "      <td>2680</td>\n",
       "      <td>354</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2684</td>\n",
       "      <td>196</td>\n",
       "      <td>214</td>\n",
       "      <td>156</td>\n",
       "      <td>6645</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15122</td>\n",
       "      <td>2683</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2654</td>\n",
       "      <td>201</td>\n",
       "      <td>216</td>\n",
       "      <td>152</td>\n",
       "      <td>6675</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "Id                                                                  \n",
       "15121       2680     354     14                                 0   \n",
       "15122       2683       0     13                                 0   \n",
       "\n",
       "       Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "Id                                                                       \n",
       "15121                               0                             2684   \n",
       "15122                               0                             2654   \n",
       "\n",
       "       Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "Id                                                    \n",
       "15121            196             214            156   \n",
       "15122            201             216            152   \n",
       "\n",
       "       Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
       "Id                                         ...                             \n",
       "15121                                6645  ...            0            0   \n",
       "15122                                6675  ...            0            0   \n",
       "\n",
       "       Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "Id                                                                       \n",
       "15121            0            0            0            0            0   \n",
       "15122            0            0            0            0            0   \n",
       "\n",
       "       Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "Id                                            \n",
       "15121            0            0            0  \n",
       "15122            0            0            0  \n",
       "\n",
       "[2 rows x 54 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Search. It took 43 minutes to run. \n",
    "The paramaters were:\n",
    "* 'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000] \n",
    "* 'max_features': ['auto', 'sqrt', 'log2', None], \n",
    "* 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], \n",
    "* 'min_samples_split': [2, 5, 9, 14], \n",
    "* 'min_samples_leaf': [2, 4, 6, 8], \n",
    "* 'bootstrap': [True, False]\n",
    "\n",
    "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
    "In GridSearchCV not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter = 100.\n",
    "\n",
    "**\n",
    "NOTE: You can run this cell (it'll take a while) or trust the output and go on to the GridSearchCV Cell and pick it up from there...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "## Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt', 'log2', None]\n",
    "## Maximum number of levels in tree\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "#max_depth.append(None)\n",
    "## Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 9, 14, ]\n",
    "## Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [2, 4, 6, 8]\n",
    "## Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]\n",
    "## Create the random grid\n",
    "#random_search = {'n_estimators': n_estimators,\n",
    "#                 'max_features': max_features,\n",
    "#                 'max_depth': max_depth,\n",
    "#                 'min_samples_split': min_samples_split,\n",
    "#                 'min_samples_leaf': min_samples_leaf,\n",
    "#                 'bootstrap': bootstrap}\n",
    "\n",
    "#print(random_search)\n",
    "## Use the random grid to search for best hyperparameters\n",
    "## First create the base model to tune\n",
    "#clf = RandomForestClassifier()\n",
    "## Random search of parameters, using 4 fold cross validation, \n",
    "## search across 100 different combinations, and use all available cores\n",
    "#model = RandomizedSearchCV(estimator = clf, param_distributions = random_search, n_iter = 100, \n",
    "#                               cv = 4, verbose= 5, random_state= 1, n_jobs = -1)\n",
    "#model.fit(X_train_full,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output was:\n",
    "\n",
    "RandomizedSearchCV(cv=4, error_score='raise-deprecating',\n",
    "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False),\n",
    "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
    "          param_distributions={'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt', 'log2', None], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 9, 14], 'min_samples_leaf': [2, 4, 6, 8], 'bootstrap': [True, False]},\n",
    "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
    "          return_train_score='warn', scoring=None, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for model.best_params was:\n",
    "\n",
    "* 'n_estimators': 2000,\n",
    "*  'min_samples_split': 2,\n",
    "*  'min_samples_leaf': 2,\n",
    "*  'max_features': 'sqrt',\n",
    "*  'max_depth': 100,\n",
    "*  'bootstrap': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of the Randomized Search\n",
    "# Search 'around' the values that the Randomized search revealed. \n",
    "#gridSearch_params = {\n",
    "#    'bootstrap': [False],\n",
    "#    'max_depth': [90, 100, 110, 120],\n",
    "#    'max_features': ['sqrt'],\n",
    "#    'min_samples_leaf': [2, 3, 4],\n",
    "#    'min_samples_split': [2, 3, 4],\n",
    "#    'n_estimators': [1900, 1950, 2000, 2050, 2100]\n",
    "#}\n",
    "## Create a base model\n",
    "#model3 = RandomForestRegressor()\n",
    "## Instantiate the GridSearch model\n",
    "#grid_search = GridSearchCV(estimator = model3, param_grid = gridSearch_params, \n",
    "#                          cv = 4, n_jobs = -1, verbose = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search. It took 92 minutes to complete. The Parameters were\n",
    "\n",
    "* 'bootstrap': False,\n",
    "*  'max_depth': 100,\n",
    "*  'max_features': 'sqrt',\n",
    "*  'min_samples_leaf': 2,\n",
    "*  'min_samples_split': 2,\n",
    "*  'n_estimators': 2100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search to the data\n",
    "#grid_search.fit(X_train_full, y_train)\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the grid_search.best_params_ method were:\n",
    "\n",
    "* bootstrap=False, criterion='mse', max_depth=100,\n",
    "*            max_features='sqrt', max_leaf_nodes=None,\n",
    "*            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "*            min_samples_leaf=2, min_samples_split=2,\n",
    "*            min_weight_fraction_leaf=0.0, n_estimators=2100, n_jobs=None,\n",
    "*            oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Random Grid Search Results. Use these as a starting point for for the Grid Search\n",
    "#'n_estimators': 2000,\n",
    "# 'min_samples_split': 2,\n",
    "# 'min_samples_leaf': 2,\n",
    "# 'max_features': 'sqrt',\n",
    "# 'max_depth': 100,\n",
    "# 'bootstrap': False\n",
    "#criterion = 'entropy'\n",
    "\n",
    "# Grid Search Results of best parameters for the \n",
    "#'bootstrap': False,\n",
    "# 'max_depth': 100,\n",
    "# 'max_features': 'sqrt',\n",
    "# 'min_samples_leaf': 2,\n",
    "# 'min_samples_split': 2,\n",
    "# 'n_estimators': 2100\n",
    "\n",
    "#Random Forest using Grid Search best predicted params.\n",
    "model = RandomForestClassifier(n_estimators = 2100, min_samples_split = 2, max_features = 'sqrt', max_depth = 100, criterion = 'entropy', \n",
    "                               bootstrap = False, random_state = 1).fit(X_train_full,y_train)\n",
    "\n",
    "model.fit(X_train_full, y_train)\n",
    "# Create target object and call it y\n",
    "####yFinal = X_test.Cover_Type\n",
    "# Create feature object and call it X. Drop what we are trying to predict\n",
    "#####XFinal = X_test.drop(columns = 'Cover_Type')\n",
    "\n",
    "predictionForest = model.predict(X_test)\n",
    "print(predictionForest)\n",
    "#print(confusion_matrix(yFinal,predictionForest))\n",
    "#print(classification_report(yFinal,predictionForest))\n",
    "#acc1 = accuracy_score(yFinal,predictionForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#mae_1 = mean_absolute_error(y_test, predictionForest)\n",
    "#print(\"Mean Absolute Error:\" , mae_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Cover_Type\n",
       "0  15121           2\n",
       "1  15122           2\n",
       "2  15123           2\n",
       "3  15124           2\n",
       "4  15125           2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.read_csv(\"/kaggle/input/learn-together/test.csv\").Id\n",
    "my_submission = pd.DataFrame({'Id': idx, 'Cover_Type': predictionForest})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "my_submission.head()\n",
    "\n",
    "##my_submission = pd.DataFrame({'Id': X_test_full.Id, 'Cover_Type': predictionForest})\n",
    "#my_submission = pd.DataFrame({'Cover_Type': predictionForest})\n",
    "## you could use any filename. We choose submission here\n",
    "#my_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
